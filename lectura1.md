# Lectura 1

#### Texto: Schafer J.B., Frankowski D., Herlocker J., Sen S. (2007) Collaborative Filtering Recommender Systems. In: Brusilovsky P., Kobsa A., Nejdl W. (eds) The Adaptive Web. Lecture Notes in Computer Science, vol 4321. Springer, Berlin, Heidelberg. https://doi.org/10.1007/978-3-540-72079-9_9

El texto define y contextualiza los filtros colaborativos como algoritmos capaces de filtrar y evaluar ítems utilizando las evaluaciones de otras personas. Luego elabora una serie de clasificaciones de los filtros colaborativos, sin embargo, la que más me llamó la tención fue la división entre algoritmos probabilísticos y no probabilísticos.

Específicamente me agradó que los filtros colaborativos probabilísticos permitían no solamente predecir las evaluaciones de los usuarios, sino que también permitían estimar una confianza asociada a cada predicción.

Respecto a los filtros colaborativos no probabilísticos, mientras leía el texto me preguntaba por qué utilizaban el coeficiente de correlación de Pearson, considerando que las evaluaciones de escala Likert típicas no necesariamente pueden ser consideradas como variables cuantitativas. Pensaba que quizás una mejor aproximación podía ser una correlación de Spearman, que realiza un ranking de las evaluaciones antes de estimar la correlación, lo cual podría mitigar en cierto sentido las diferentes interpretaciones que podrían tener los usuarios de las escalas. Sin embargo, al avanzar en el texto me fijé que los autores incorporan una corrección en ese estilo en la ecuación (4).

Por otro lado, un aspecto importante que está presente en todo el texto es la discusión respecto a la persistencia de los ítems y de los gustos. En general uno supone que es difícil que las nuevas tendencias sean explícitamente evaluadas por los usuarios. Esto sugiere que los CF deberían utilizar evaluaciones implícitas de los ítems para poder evolucionar y adaptarse rápidamente a los nuevos ítems y gustos. Respecto a esto, el texto sugiere que no es necesario que una gran cantidad de usuarios estén constantemente evaluando cada nuevo ítem, sino que lo que se necesita es un pequeño conjunto de usuarios denominados “early adopters”, los cuales a través de sus rápidas evaluaciones permitirían estimar o predecir ratings para otros usuarios menos activos. De todas formas, pienso que este supuesto tiene un problema, pues no podemos suponer que los gustos de los “early adopters” se distribuyen de igual manera que los gustos de los usuarios menos activos, lo cual podría sesgar nuestras estimaciones o predicciones.

Finalmente, otro aspecto que me pareció interesante es la falta de consenso que existe para una métrica de evaluación. A diferencia de otras áreas donde la predicción y la escalabilidad es la clave, en el área de los sistemas recomendadores parece haber poco consenso debido a que son algoritmos que interactúan directamente con usuarios, por lo que parece adecuado incorporar a estos en su evaluación y eso abre un mundo de posibilidades, pero también supongo que genera una tremenda dificultad para estandarizar las evaluaciones.
